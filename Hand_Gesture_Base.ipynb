{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Hand Gesture_Base.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "from imageio import imread\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:04.622278Z",
          "iopub.execute_input": "2022-02-14T14:19:04.622713Z",
          "iopub.status.idle": "2022-02-14T14:19:05.650661Z",
          "shell.execute_reply.started": "2022-02-14T14:19:04.622673Z",
          "shell.execute_reply": "2022-02-14T14:19:05.649232Z"
        },
        "trusted": true,
        "id": "qoN1YskGtKo0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:05.653569Z",
          "iopub.execute_input": "2022-02-14T14:19:05.654058Z",
          "iopub.status.idle": "2022-02-14T14:19:11.233049Z",
          "shell.execute_reply.started": "2022-02-14T14:19:05.654007Z",
          "shell.execute_reply": "2022-02-14T14:19:11.231649Z"
        },
        "trusted": true,
        "id": "Ay0m0mxatKo3"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc = np.random.permutation(open('../content/drive/MyDrive/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('../content/drive/MyDrive/val.csv').readlines())\n",
        "batch_size = 64"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:11.282134Z",
          "iopub.execute_input": "2022-02-14T14:19:11.282926Z",
          "iopub.status.idle": "2022-02-14T14:19:11.305233Z",
          "shell.execute_reply.started": "2022-02-14T14:19:11.282825Z",
          "shell.execute_reply": "2022-02-14T14:19:11.303834Z"
        },
        "trusted": true,
        "id": "gyoyzH_VtKo4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataPreprocessing"
      ],
      "metadata": {
        "id": "9HiuH-uMPDbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cropResize(image, y, z):\n",
        "    h, w = image.shape\n",
        "    \n",
        "    # if smaller image crop at center for 120x120\n",
        "    if w == 160:\n",
        "        image = image[:120, 20:140]\n",
        "\n",
        "    # resize every image\n",
        "    return resize(image, (y,z))"
      ],
      "metadata": {
        "id": "1xrANziuvu_x",
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:12.072865Z",
          "iopub.execute_input": "2022-02-14T14:19:12.073185Z",
          "iopub.status.idle": "2022-02-14T14:19:12.080537Z",
          "shell.execute_reply.started": "2022-02-14T14:19:12.073151Z",
          "shell.execute_reply": "2022-02-14T14:19:12.079456Z"
        },
        "trusted": true
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizeImage(image):\n",
        "    # applying normalization\n",
        "    return image/255.0"
      ],
      "metadata": {
        "id": "KhGrETufvu_y",
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:12.082204Z",
          "iopub.execute_input": "2022-02-14T14:19:12.082563Z",
          "iopub.status.idle": "2022-02-14T14:19:12.093746Z",
          "shell.execute_reply.started": "2022-02-14T14:19:12.082529Z",
          "shell.execute_reply": "2022-02-14T14:19:12.092910Z"
        },
        "trusted": true
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessImage(image, y, z):\n",
        "    return normalizeImage(cropResize(image, y, z))"
      ],
      "metadata": {
        "id": "-qd1bxIZvu_y",
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:12.095006Z",
          "iopub.execute_input": "2022-02-14T14:19:12.095307Z",
          "iopub.status.idle": "2022-02-14T14:19:12.105293Z",
          "shell.execute_reply.started": "2022-02-14T14:19:12.095277Z",
          "shell.execute_reply": "2022-02-14T14:19:12.104432Z"
        },
        "trusted": true
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBatchData(source_path, t, batch, batch_size, img_tensor):\n",
        "    [x,y,z] = [len(img_tensor[0]),img_tensor[1], img_tensor[2]]\n",
        "    img_idx = img_tensor[0]\n",
        "    batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "    for folder in range(batch_size): # iterate over the batch_size\n",
        "        imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "        for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "            image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "            #crop the images and resize them. Note that the images are of 2 different shape \n",
        "            #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "\n",
        "            # separate preprocessImage function is defined for cropping, resizing and normalizing images\n",
        "            batch_data[folder,idx,:,:,0] = preprocessImage(image[:, :, 0], y, z)\n",
        "            batch_data[folder,idx,:,:,1] = preprocessImage(image[:, :, 1], y, z)\n",
        "            batch_data[folder,idx,:,:,2] = preprocessImage(image[:, :, 2], y, z)\n",
        "\n",
        "        batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "    return batch_data, batch_labels"
      ],
      "metadata": {
        "id": "-yPBgXECvu_z",
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:12.119142Z",
          "iopub.execute_input": "2022-02-14T14:19:12.119450Z",
          "iopub.status.idle": "2022-02-14T14:19:12.136958Z",
          "shell.execute_reply.started": "2022-02-14T14:19:12.119409Z",
          "shell.execute_reply": "2022-02-14T14:19:12.135782Z"
        },
        "trusted": true
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator"
      ],
      "metadata": {
        "id": "_xgm_a-gPKdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(source_path, folder_list, batch_size, img_tensor):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = int(len(folder_list)/batch_size)\n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            yield getBatchData(source_path, t, batch, batch_size, img_tensor)\n",
        "        \n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "        # checking if any remaining batches are there or not\n",
        "        if len(folder_list)%batch_size != 0:\n",
        "            # updated the batch size and yield\n",
        "            batch_size = len(folder_list)%batch_size\n",
        "            yield getBatchData(source_path, t, batch, batch_size, img_tensor)"
      ],
      "metadata": {
        "id": "eA6r1IMmvu_0",
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:12.139410Z",
          "iopub.execute_input": "2022-02-14T14:19:12.139769Z",
          "iopub.status.idle": "2022-02-14T14:19:12.154141Z",
          "shell.execute_reply.started": "2022-02-14T14:19:12.139737Z",
          "shell.execute_reply": "2022-02-14T14:19:12.153041Z"
        },
        "trusted": true
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '../content/drive/MyDrive/train'\n",
        "val_path = '../content/drive/MyDrive/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 10\n",
        "print ('# epochs =', num_epochs)"
      ],
      "metadata": {
        "id": "V8gjkDqoQG9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getImgTensor(n_frames):\n",
        "    img_idx = np.round(np.linspace(0, 29, n_frames)).astype(int)\n",
        "    return [img_idx, 100, 100, 3]\n",
        "\n",
        "# define image tensor size\n",
        "img_tensor = getImgTensor(20)\n",
        "print ('# img_tensor =', img_tensor)"
      ],
      "metadata": {
        "id": "salGNL8vP_9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check complete batch shape\n",
        "sample_generator = generator(train_path, train_doc, batch_size, img_tensor)\n",
        "sample_batch_data, sample_batch_labels = next(sample_generator)\n",
        "print(sample_batch_data.shape)\n",
        "\n",
        "# validation batch sample\n",
        "sample_val_generator = generator(val_path, val_doc, batch_size, img_tensor)\n",
        "sample_val_batch_data, sample_val_batch_labels = next(sample_val_generator)\n",
        "print(sample_val_batch_data.shape)"
      ],
      "metadata": {
        "id": "qG_Ny21VPbrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot generated sample images\n",
        "fig, ax = plt.subplots(1,2)\n",
        "ax[0].imshow(sample_val_batch_data[16,10,:,:,:])   \n",
        "ax[1].imshow(sample_val_batch_data[25,10,:,:,:])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B5kBhDpDPieh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_tensor)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_tensor)\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1"
      ],
      "metadata": {
        "id": "NhrMx0uZPok9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Callback"
      ],
      "metadata": {
        "id": "3dm2iQcoPyS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "\n",
        "callbacks_list = [LR]"
      ],
      "metadata": {
        "id": "kg4jXDsIPvlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base Model"
      ],
      "metadata": {
        "id": "9A0Y13yhvvAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make3dFilter(x):\n",
        "    return tuple([x]*3)\n",
        "\n",
        "def make2dFilter(x):\n",
        "    return tuple([x]*2)"
      ],
      "metadata": {
        "id": "LNgZq2e-vu_z",
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:12.106397Z",
          "iopub.execute_input": "2022-02-14T14:19:12.106700Z",
          "iopub.status.idle": "2022-02-14T14:19:12.117799Z",
          "shell.execute_reply.started": "2022-02-14T14:19:12.106668Z",
          "shell.execute_reply": "2022-02-14T14:19:12.116900Z"
        },
        "trusted": true
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_frames = 16\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "\n",
        "img_tensor = getImgTensor(n_frames)\n",
        "train_generator = generator(train_path, train_doc, batch_size, img_tensor)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_tensor)\n",
        "  \n",
        "inputShape = (len(img_tensor[0]), img_tensor[1], img_tensor[2], img_tensor[3])\n",
        "\n",
        "model1 = Sequential([\n",
        "    Conv3D(16, make3dFilter(5), activation='relu', input_shape=inputShape),\n",
        "    MaxPooling3D(make3dFilter(2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv3D(32, make3dFilter(3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(1,2,2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv3D(64, make3dFilter(3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(1,2,2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Dense(5, activation='softmax')\n",
        "], name=\"conv_3d1\")\n",
        "\n",
        "model1.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print(model1.summary())\n",
        "\n",
        "model1_history = model1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "            callbacks=callbacks_list, validation_data=val_generator, validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "id": "e9Z5A_HNZgyP",
        "execution": {
          "iopub.status.busy": "2022-02-14T14:19:50.993869Z",
          "iopub.execute_input": "2022-02-14T14:19:50.994199Z",
          "iopub.status.idle": "2022-02-14T15:02:00.454793Z",
          "shell.execute_reply.started": "2022-02-14T14:19:50.994165Z",
          "shell.execute_reply": "2022-02-14T15:02:00.453684Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Model"
      ],
      "metadata": {
        "id": "kqIQiAh5Sw2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotModelHistory(h):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15,4))\n",
        "    ax[0].plot(h.history['loss'])   \n",
        "    ax[0].plot(h.history['val_loss'])\n",
        "    ax[0].legend(['loss','val_loss'])\n",
        "    ax[0].title.set_text(\"Train loss vs Validation loss\")\n",
        "\n",
        "    ax[1].plot(h.history['categorical_accuracy'])   \n",
        "    ax[1].plot(h.history['val_categorical_accuracy'])\n",
        "    ax[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n",
        "    ax[1].title.set_text(\"Train accuracy vs Validation accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Max. Training Accuracy\", max(h.history['categorical_accuracy']))\n",
        "    print(\"Max. Validaiton Accuracy\", max(h.history['val_categorical_accuracy']))\n",
        "\n",
        "plotModelHistory(model1_history)"
      ],
      "metadata": {
        "id": "oKY1gr-wPlYW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}